<*
	[AUTOMATICALLY GENERATED BY C3PG]
	Parser implementation for: Lexer
*>
module c3pg::lexer_grammar::parser;

/* STANDARD IMPORTS */

import c3pg::runtime;
import std::collections::list;

/* LEXER IMPORT */

import c3pg::lexer_grammar::lexer;

/* NODE CHILD TYPE */

struct LexerNodeChild
{
	bool is_terminal;
	union
	{
		LexerToken terminal;
		LexerNode* nonterminal;
	}
}

/* NODE CONTEXTS */

struct NextStateContext
{
	LexerToken name;
}

fn void NextStateContext.free(&self, Allocator a) @inline
{
}

struct ModeContext
{
	LexerNode*[] terminal;
	LexerToken name;
	LexerToken[] err;
}

fn void ModeContext.free(&self, Allocator a) @inline
{
	allocator::free(a, self.terminal);
	allocator::free(a, self.err);
}

struct StringContext
{
	LexerToken[] contents;
}

fn void StringContext.free(&self, Allocator a) @inline
{
	allocator::free(a, self.contents);
}

struct LexerDefinitionContext
{
	LexerNode*[] lexer_info;
}

fn void LexerDefinitionContext.free(&self, Allocator a) @inline
{
	allocator::free(a, self.lexer_info);
}

struct LexerInfoContext
{
	LexerNode* namespaced_info;
	LexerToken name;
}

fn void LexerInfoContext.free(&self, Allocator a) @inline
{
}

struct NamedTerminalContext
{
	LexerNode*[] next_state;
	LexerToken name;
}

fn void NamedTerminalContext.free(&self, Allocator a) @inline
{
	allocator::free(a, self.next_state);
}

struct DropTerminalContext
{
	LexerNode*[] next_state;
}

fn void DropTerminalContext.free(&self, Allocator a) @inline
{
	allocator::free(a, self.next_state);
}

struct TerminalIdentContext
{
	LexerToken name;
}

fn void TerminalIdentContext.free(&self, Allocator a) @inline
{
}

struct RootContext
{
	LexerNode*[] mode;
	LexerNode*[] terminal;
	LexerNode* lexer_definition;
}

fn void RootContext.free(&self, Allocator a) @inline
{
	allocator::free(a, self.mode);
	allocator::free(a, self.terminal);
}

struct TerminalContext
{
	LexerNode* pattern;
	LexerNode* terminal_type;
}

fn void TerminalContext.free(&self, Allocator a) @inline
{
}

struct NamespacedInfoContext
{
	LexerToken[] children;
}

fn void NamespacedInfoContext.free(&self, Allocator a) @inline
{
	allocator::free(a, self.children);
}

struct ErrorTerminalContext
{
	LexerNode*[] next_state;
	LexerNode* string;
	LexerNode* e;
}

fn void ErrorTerminalContext.free(&self, Allocator a) @inline
{
	allocator::free(a, self.next_state);
}

struct RegexContext
{
	LexerToken[] contents;
}

fn void RegexContext.free(&self, Allocator a) @inline
{
	allocator::free(a, self.contents);
}

/* NODE TYPES */

enum LexerNodeT
{
	NEXT_STATE,
	MODE,
	STRING,
	LEXER_DEFINITION,
	LEXER_INFO,
	NAMED_TERMINAL,
	DROP_TERMINAL,
	TERMINAL_IDENT,
	ROOT,
	TERMINAL,
	NAMESPACED_INFO,
	ERROR_TERMINAL,
	REGEX,
}

/* NODE TYPE */

struct LexerNode
{
	LexerNodeT type;
	Span span;
	LexerNodeChild[] children;
	union
	{
		NextStateContext next_state;
		ModeContext mode;
		StringContext string;
		LexerDefinitionContext lexer_definition;
		LexerInfoContext lexer_info;
		NamedTerminalContext named_terminal;
		DropTerminalContext drop_terminal;
		TerminalIdentContext terminal_ident;
		RootContext root;
		TerminalContext terminal;
		NamespacedInfoContext namespaced_info;
		ErrorTerminalContext error_terminal;
		RegexContext regex;
	}
}

fn void LexerNode.free(&self, Allocator a)
{
	foreach (child : self.children)
	{
		if (!child.is_terminal)
		{
			child.nonterminal.free(a);
		}
	}
	allocator::free(a, self.children);
	switch (self.type)
	{
		case NEXT_STATE:
			self.next_state.free(a);
		case MODE:
			self.mode.free(a);
		case STRING:
			self.string.free(a);
		case LEXER_DEFINITION:
			self.lexer_definition.free(a);
		case LEXER_INFO:
			self.lexer_info.free(a);
		case NAMED_TERMINAL:
			self.named_terminal.free(a);
		case DROP_TERMINAL:
			self.drop_terminal.free(a);
		case TERMINAL_IDENT:
			self.terminal_ident.free(a);
		case ROOT:
			self.root.free(a);
		case TERMINAL:
			self.terminal.free(a);
		case NAMESPACED_INFO:
			self.namespaced_info.free(a);
		case ERROR_TERMINAL:
			self.error_terminal.free(a);
		case REGEX:
			self.regex.free(a);
		default:
	}
	allocator::free(a, self);
}

/* PARSER CONTEXT */

struct LexerParser
{
	LexerLexer* lexer;
	Allocator allocator;
	C3PgLogger logger;
	bool primed;
}

/* PARSER FUNCTIONS */

fn LexerParser create_lexer_parser(LexerLexer* lexer, Allocator allocator = mem, C3PgLogger logger = null)
{
	return {lexer, allocator, logger, false};
}

fn LexerToken? LexerParser.peek(&self) @inline @private
{
	if (!self.primed)
	{
		self.primed = true;
		self.lexer.advance()!;
	}
	return self.lexer.current;
}

fn LexerTokenT? LexerParser.peek_t(&self) @inline @private
{
	return self.peek()!.type;
}

fn Span? LexerParser.next(&self, Span current) @inline @private
{
	Span result = self.peek()!.span;
	if (current.begin != usz.max) result = current + result;
	self.lexer.advance()!;
	return result;
}

fn void LexerParser.log_at(&self, Span s, String message) @inline @private
{
	if (self.logger != null) self.logger.log_error(s,message,self.lexer.file,self.lexer.file_data);
}

fn void LexerParser.log_current(&self, String message) @inline @private
{
	self.log_at(self.lexer.current.span, message);
}

fn void LexerParser.log_unexpected(&self, String expected) @inline @private
{
	self.log_current(string::tformat(`Unexpected token "%s", expected %s;`, runtime::get_terminal_name(self.peek_t()!!), expected));
}

macro bool? LexerParser.peek_is(&self, ...) @private
{
	var current = self.peek_t()!;
	return runtime::is_any_of(current, $vasplat);
}

macro Span? LexerParser.expect(&self, Span current_span, ...) @private
{
	if (self.peek_is($vasplat)!)
	{
		return self.next(current_span);
	}
	self.log_unexpected(runtime::get_expected_sequence($vasplat));
	return runtime::UNEXPECTED_TOKEN?;
}

fn LexerNode*? LexerParser.parse_next_state(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		LexerToken name;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.LPAREN)!;
		c.push({.is_terminal = true, .terminal = self.peek()!});
		name = c[^1].terminal;
		s = self.expect(s,LexerTokenT.IDENT)!;
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.RPAREN)!;

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = NEXT_STATE;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.next_state.name = name;
		return r;
	};
}


fn LexerNode*? LexerParser.parse_pattern(&self)
{
	if (self.peek_is(LexerTokenT.STRING_BEGIN)!)
	{
		return self.parse_string();
	}
	if (self.peek_is(LexerTokenT.REGEX_BEGIN)!)
	{
		return self.parse_regex();
	}
	self.log_unexpected(runtime::get_expected_sequence(LexerTokenT.REGEX_BEGIN, LexerTokenT.STRING_BEGIN));
	return runtime::UNEXPECTED_TOKEN?;
}


fn LexerNode*? LexerParser.parse_terminal_type(&self)
{
	if (self.peek_is(LexerTokenT.IDENT)!)
	{
		return self.parse_named_terminal();
	}
	if (self.peek_is(LexerTokenT.DROP)!)
	{
		return self.parse_drop_terminal();
	}
	if (self.peek_is(LexerTokenT.ERROR)!)
	{
		return self.parse_error_terminal();
	}
	self.log_unexpected(runtime::get_expected_sequence(LexerTokenT.ERROR, LexerTokenT.DROP, LexerTokenT.IDENT));
	return runtime::UNEXPECTED_TOKEN?;
}


fn LexerNode*? LexerParser.parse_mode(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		List { LexerNode* } terminal;
		LexerToken name;
		List { LexerToken } err;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.MODE)!;
		if (self.peek_is(MODE_ERRORS)!)
		{
			c.push({.is_terminal = true, .terminal = self.peek()!});
			err.push(c[^1].terminal);
			s = self.expect(s,LexerTokenT.MODE_ERRORS)!;
		}
		c.push({.is_terminal = true, .terminal = self.peek()!});
		name = c[^1].terminal;
		s = self.expect(s,LexerTokenT.IDENT)!;
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.MODE_BEGIN)!;
		do
		{
			c.push({.is_terminal = false, .nonterminal = self.parse_terminal()!});
			terminal.push(c[^1].nonterminal);
			s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;
		} while (self.peek_is(LexerTokenT.ERROR, LexerTokenT.DROP, LexerTokenT.IDENT)!);

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = MODE;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.mode.terminal = terminal.to_array(self.allocator);
		r.mode.name = name;
		r.mode.err = err.to_array(self.allocator);
		return r;
	};
}


fn LexerNode*? LexerParser.parse_string(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		List { LexerToken } contents;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.STRING_BEGIN)!;
		do
		{
			c.push({.is_terminal = true, .terminal = self.peek()!});
			contents.push(c[^1].terminal);
			s = self.expect(s,LexerTokenT.CHARACTER)!;
		} while (self.peek_is(CHARACTER)!);
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.STRING_END)!;

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = STRING;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.string.contents = contents.to_array(self.allocator);
		return r;
	};
}


fn LexerNode*? LexerParser.parse_lexer_definition(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		List { LexerNode* } lexer_info;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.LEXER_IDENTIFIER)!;
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.BEGIN_INFORMATION)!;
		while (self.peek_is(LexerTokenT.INFORMATION_IDENT)!)
		{
			c.push({.is_terminal = false, .nonterminal = self.parse_lexer_info()!});
			lexer_info.push(c[^1].nonterminal);
			s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;
		}
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.END_INFORMATION)!;

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = LEXER_DEFINITION;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.lexer_definition.lexer_info = lexer_info.to_array(self.allocator);
		return r;
	};
}


fn LexerNode*? LexerParser.parse_lexer_info(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		LexerNode* namespaced_info;
		LexerToken name;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = true, .terminal = self.peek()!});
		name = c[^1].terminal;
		s = self.expect(s,LexerTokenT.INFORMATION_IDENT)!;
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.INFORMATION_SEPARATOR)!;
		c.push({.is_terminal = false, .nonterminal = self.parse_namespaced_info()!});
		namespaced_info = c[^1].nonterminal;
		s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = LEXER_INFO;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.lexer_info.namespaced_info = namespaced_info;
		r.lexer_info.name = name;
		return r;
	};
}


fn LexerNode*? LexerParser.parse_named_terminal(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		List { LexerNode* } next_state;
		LexerToken name;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = true, .terminal = self.peek()!});
		name = c[^1].terminal;
		s = self.expect(s,LexerTokenT.IDENT)!;
		if (self.peek_is(LexerTokenT.LPAREN)!)
		{
			c.push({.is_terminal = false, .nonterminal = self.parse_next_state()!});
			next_state.push(c[^1].nonterminal);
			s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;
		}

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = NAMED_TERMINAL;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.named_terminal.next_state = next_state.to_array(self.allocator);
		r.named_terminal.name = name;
		return r;
	};
}


fn LexerNode*? LexerParser.parse_drop_terminal(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		List { LexerNode* } next_state;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.DROP)!;
		if (self.peek_is(LexerTokenT.LPAREN)!)
		{
			c.push({.is_terminal = false, .nonterminal = self.parse_next_state()!});
			next_state.push(c[^1].nonterminal);
			s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;
		}

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = DROP_TERMINAL;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.drop_terminal.next_state = next_state.to_array(self.allocator);
		return r;
	};
}


fn LexerNode*? LexerParser.parse_terminal_ident(&self)
{
	if (self.peek_is(LexerTokenT.IDENT)!)
	{
		@pool()
		{
			/* setup returned fields and returned information */
			Span s = {usz.max,usz.max};
			List { LexerNodeChild } c;
			LexerToken name;

			/* make sure that the tree doesn't get leaked on a failed parse */
			defer catch
			{
				foreach (n : c)
				{
					if (!n.is_terminal)
					{
						n.nonterminal.free(self.allocator);
					}
				}
			}

			/* attempt to parse the node */
			c.push({.is_terminal = true, .terminal = self.peek()!});
			name = c[^1].terminal;
			s = self.expect(s,LexerTokenT.IDENT)!;

			/* construct the parsed node from the returned fields and information */
			LexerNode* r = allocator::new(self.allocator, LexerNode);
			r.type = TERMINAL_IDENT;
			r.span = s;
			r.children = c.to_array(self.allocator);
			r.terminal_ident.name = name;
			return r;
		};
	}
	if (self.peek_is(LexerTokenT.DROP)!)
	{
		@pool()
		{
			/* setup returned fields and returned information */
			Span s = {usz.max,usz.max};
			List { LexerNodeChild } c;
			LexerToken name;

			/* make sure that the tree doesn't get leaked on a failed parse */
			defer catch
			{
				foreach (n : c)
				{
					if (!n.is_terminal)
					{
						n.nonterminal.free(self.allocator);
					}
				}
			}

			/* attempt to parse the node */
			c.push({.is_terminal = true, .terminal = self.peek()!});
			s = self.expect(s,LexerTokenT.DROP)!;

			/* construct the parsed node from the returned fields and information */
			LexerNode* r = allocator::new(self.allocator, LexerNode);
			r.type = TERMINAL_IDENT;
			r.span = s;
			r.children = c.to_array(self.allocator);
			r.terminal_ident.name = name;
			return r;
		};
	}
	if (self.peek_is(LexerTokenT.ERROR)!)
	{
		@pool()
		{
			/* setup returned fields and returned information */
			Span s = {usz.max,usz.max};
			List { LexerNodeChild } c;
			LexerToken name;

			/* make sure that the tree doesn't get leaked on a failed parse */
			defer catch
			{
				foreach (n : c)
				{
					if (!n.is_terminal)
					{
						n.nonterminal.free(self.allocator);
					}
				}
			}

			/* attempt to parse the node */
			c.push({.is_terminal = true, .terminal = self.peek()!});
			s = self.expect(s,LexerTokenT.ERROR)!;

			/* construct the parsed node from the returned fields and information */
			LexerNode* r = allocator::new(self.allocator, LexerNode);
			r.type = TERMINAL_IDENT;
			r.span = s;
			r.children = c.to_array(self.allocator);
			r.terminal_ident.name = name;
			return r;
		};
	}
	self.log_unexpected(runtime::get_expected_sequence(LexerTokenT.ERROR, LexerTokenT.DROP, LexerTokenT.IDENT));
	return runtime::UNEXPECTED_TOKEN?;
}


fn LexerNode*? LexerParser.parse_root(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		List { LexerNode* } mode;
		List { LexerNode* } terminal;
		LexerNode* lexer_definition;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = false, .nonterminal = self.parse_lexer_definition()!});
		lexer_definition = c[^1].nonterminal;
		s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;
		do
		{
			c.push({.is_terminal = false, .nonterminal = self.parse_terminal()!});
			terminal.push(c[^1].nonterminal);
			s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;
		} while (self.peek_is(LexerTokenT.ERROR, LexerTokenT.DROP, LexerTokenT.IDENT)!);
		while (self.peek_is(LexerTokenT.MODE)!)
		{
			c.push({.is_terminal = false, .nonterminal = self.parse_mode()!});
			mode.push(c[^1].nonterminal);
			s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;
		}
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.EOF)!;

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = ROOT;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.root.mode = mode.to_array(self.allocator);
		r.root.terminal = terminal.to_array(self.allocator);
		r.root.lexer_definition = lexer_definition;
		return r;
	};
}


fn LexerNode*? LexerParser.parse_terminal(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		LexerNode* pattern;
		LexerNode* terminal_type;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = false, .nonterminal = self.parse_terminal_type()!});
		terminal_type = c[^1].nonterminal;
		s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.DEFINITION)!;
		c.push({.is_terminal = false, .nonterminal = self.parse_pattern()!});
		pattern = c[^1].nonterminal;
		s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = TERMINAL;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.terminal.pattern = pattern;
		r.terminal.terminal_type = terminal_type;
		return r;
	};
}


fn LexerNode*? LexerParser.parse_namespaced_info(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		List { LexerToken } children;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = true, .terminal = self.peek()!});
		children.push(c[^1].terminal);
		s = self.expect(s,LexerTokenT.INFORMATION_IDENT)!;
		while (self.peek_is(LexerTokenT.INFORMATION_NAMESPACE)!)
		{
			c.push({.is_terminal = true, .terminal = self.peek()!});
			s = self.expect(s,LexerTokenT.INFORMATION_NAMESPACE)!;
			c.push({.is_terminal = true, .terminal = self.peek()!});
			children.push(c[^1].terminal);
			s = self.expect(s,LexerTokenT.INFORMATION_IDENT)!;
		}

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = NAMESPACED_INFO;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.namespaced_info.children = children.to_array(self.allocator);
		return r;
	};
}


fn LexerNode*? LexerParser.parse_error_terminal(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		List { LexerNode* } next_state;
		LexerNode* string;
		LexerNode* e;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.ERROR)!;
		if (self.peek_is(LexerTokenT.LPAREN)!)
		{
			c.push({.is_terminal = false, .nonterminal = self.parse_next_state()!});
			next_state.push(c[^1].nonterminal);
			s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;
		}
		if (self.peek_is(LexerTokenT.MODE_ERRORS)!)
		{
			c.push({.is_terminal = true, .terminal = self.peek()!});
			s = self.expect(s,LexerTokenT.MODE_ERRORS)!;
			c.push({.is_terminal = false, .nonterminal = self.parse_string()!});
			e = c[^1].nonterminal;
			string = c[^1].nonterminal;
			s = s.begin == usz.max ? c[^1].nonterminal.span : s + c[^1].nonterminal.span;
		}

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = ERROR_TERMINAL;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.error_terminal.next_state = next_state.to_array(self.allocator);
		r.error_terminal.string = string;
		r.error_terminal.e = e;
		return r;
	};
}


fn LexerNode*? LexerParser.parse_regex(&self)
{
	@pool()
	{
		/* setup returned fields and returned information */
		Span s = {usz.max,usz.max};
		List { LexerNodeChild } c;
		List { LexerToken } contents;

		/* make sure that the tree doesn't get leaked on a failed parse */
		defer catch
		{
			foreach (n : c)
			{
				if (!n.is_terminal)
				{
					n.nonterminal.free(self.allocator);
				}
			}
		}

		/* attempt to parse the node */
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.REGEX_BEGIN)!;
		do
		{
			c.push({.is_terminal = true, .terminal = self.peek()!});
			contents.push(c[^1].terminal);
			s = self.expect(s,LexerTokenT.CHARACTER)!;
		} while (self.peek_is(CHARACTER)!);
		c.push({.is_terminal = true, .terminal = self.peek()!});
		s = self.expect(s,LexerTokenT.REGEX_END)!;

		/* construct the parsed node from the returned fields and information */
		LexerNode* r = allocator::new(self.allocator, LexerNode);
		r.type = REGEX;
		r.span = s;
		r.children = c.to_array(self.allocator);
		r.regex.contents = contents.to_array(self.allocator);
		return r;
	};
}


/* VISITOR METHODS */

interface LexerVisitor
{
	fn any? visit_next_state(LexerNode* node, NextStateContext* node_ctx, any ctx=null) @optional;
	fn any? visit_mode(LexerNode* node, ModeContext* node_ctx, any ctx=null) @optional;
	fn any? visit_string(LexerNode* node, StringContext* node_ctx, any ctx=null) @optional;
	fn any? visit_lexer_definition(LexerNode* node, LexerDefinitionContext* node_ctx, any ctx=null) @optional;
	fn any? visit_lexer_info(LexerNode* node, LexerInfoContext* node_ctx, any ctx=null) @optional;
	fn any? visit_named_terminal(LexerNode* node, NamedTerminalContext* node_ctx, any ctx=null) @optional;
	fn any? visit_drop_terminal(LexerNode* node, DropTerminalContext* node_ctx, any ctx=null) @optional;
	fn any? visit_terminal_ident(LexerNode* node, TerminalIdentContext* node_ctx, any ctx=null) @optional;
	fn any? visit_root(LexerNode* node, RootContext* node_ctx, any ctx=null) @optional;
	fn any? visit_terminal(LexerNode* node, TerminalContext* node_ctx, any ctx=null) @optional;
	fn any? visit_namespaced_info(LexerNode* node, NamespacedInfoContext* node_ctx, any ctx=null) @optional;
	fn any? visit_error_terminal(LexerNode* node, ErrorTerminalContext* node_ctx, any ctx=null) @optional;
	fn any? visit_regex(LexerNode* node, RegexContext* node_ctx, any ctx=null) @optional;
}

fn any? LexerNode.visit(&self, LexerVisitor visitor, any ctx=null)
{
	switch (self.type)
	{
		case NEXT_STATE:
			return &visitor.visit_next_state ? visitor.visit_next_state(self, &self.next_state, ctx) : self.visit_children(visitor, ctx);
		case MODE:
			return &visitor.visit_mode ? visitor.visit_mode(self, &self.mode, ctx) : self.visit_children(visitor, ctx);
		case STRING:
			return &visitor.visit_string ? visitor.visit_string(self, &self.string, ctx) : self.visit_children(visitor, ctx);
		case LEXER_DEFINITION:
			return &visitor.visit_lexer_definition ? visitor.visit_lexer_definition(self, &self.lexer_definition, ctx) : self.visit_children(visitor, ctx);
		case LEXER_INFO:
			return &visitor.visit_lexer_info ? visitor.visit_lexer_info(self, &self.lexer_info, ctx) : self.visit_children(visitor, ctx);
		case NAMED_TERMINAL:
			return &visitor.visit_named_terminal ? visitor.visit_named_terminal(self, &self.named_terminal, ctx) : self.visit_children(visitor, ctx);
		case DROP_TERMINAL:
			return &visitor.visit_drop_terminal ? visitor.visit_drop_terminal(self, &self.drop_terminal, ctx) : self.visit_children(visitor, ctx);
		case TERMINAL_IDENT:
			return &visitor.visit_terminal_ident ? visitor.visit_terminal_ident(self, &self.terminal_ident, ctx) : self.visit_children(visitor, ctx);
		case ROOT:
			return &visitor.visit_root ? visitor.visit_root(self, &self.root, ctx) : self.visit_children(visitor, ctx);
		case TERMINAL:
			return &visitor.visit_terminal ? visitor.visit_terminal(self, &self.terminal, ctx) : self.visit_children(visitor, ctx);
		case NAMESPACED_INFO:
			return &visitor.visit_namespaced_info ? visitor.visit_namespaced_info(self, &self.namespaced_info, ctx) : self.visit_children(visitor, ctx);
		case ERROR_TERMINAL:
			return &visitor.visit_error_terminal ? visitor.visit_error_terminal(self, &self.error_terminal, ctx) : self.visit_children(visitor, ctx);
		case REGEX:
			return &visitor.visit_regex ? visitor.visit_regex(self, &self.regex, ctx) : self.visit_children(visitor, ctx);
	}
}

fn any? LexerNode.visit_children(&self, LexerVisitor visitor, any ctx=null)
{
	any result = null;
	foreach (child : self.children)
	{
		if (!child.is_terminal)
		{
			result = child.nonterminal.visit(visitor, ctx)!;
		}
	}
	return result;
}
